# WebCrawler

Написать приложение-вебкраулер, которое принимает на вход 2 аргумента: адрес сайта и максимальную глубину прохода, 
проходит по ссылкам на заданную глубину и сохраняет в БД значения: адрес страницы, содержимое страницы в текстовом виде.

Прочие условия:
* Приложение должно быть написано на Java.
* Собираться с помощью Gradle.
* Обход ссылок должен быть выполнен с использованием нескольких потоков (конфигурационный параметр).
* Предусмотреть возможность указания очень большой вложенности, БД для хранения встроенная - H2 или HSQLDB.
* Возможность продолжения обхода после внезапной остановки приложения не требуется.
* Поддержка JavaScript не требуется.
* Графический интерфейс не требуется.
* Разрешается использовать любые библиотеки для работы с HTTP, HTML, БД и так далее, нельзя только использовать готовые компоненты с функциональностью, аналогичной заданию.
* Можно использовать Jsoup и ExecutorService.
* В проверке задания будет учитываться не только работоспособность, но и качество кода. 
* Большим плюсом будет написание юнит-тестов к приложению.

Сборка проекта: gradle jar
Запуск проекта: java -jar WebCrawler-all-1.0.jar site_url depth (например, java -jar WebCrawler-all-1.0.jar http://www.adlr.ru 2)